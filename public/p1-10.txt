Paper1 Practical 10
Apply SVM on Iris dataset. Display Confusion matrix, accuracy score. Apply hyper parameter tunning on the dataset. Use the parameters (&#39;C&#39;: [0.001, 0.1, 1],&#39;kernel&#39; : [&#39;linear&#39;, &#39;poly&#39;, &#39;rbf&#39;]). Display best parameters, best estimator and best score.


import warnings
warnings.simplefilter("ignore")
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

df=pd.read_csv("D:\Downloads\Iris.csv")
df

df.columns
df.shape
df.info()

df.Species.unique()
X=df.drop(['Id','Species'],axis=1)
y=df.Species

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)
models=[]
models.append(('LR',LogisticRegression(solver='liblinear',multi_class='ovr')))
models.append(('CART',DecisionTreeClassifier()))
models.append(('NB',GaussianNB()))
models.append(('SVM',SVC(gamma='auto')))

models

results=[]
names=[]
for name,model in models:
  kfold=StratifiedKFold(n_splits=10,random_state=1,shuffle=True)
  cv_results=cross_val_score(model,X_train,y_train,cv=kfold, scoring='accuracy')
  results.append(cv_results)
  names.append(name)
  print(name,cv_results.mean(),cv_results.std())

#compare algorithms
plt.boxplot(results,labels=names)
plt.title("Algorithm Comparison")
plt.show()

model=SVC(gamma='auto')
model.fit(X_train,y_train)
y_pred=model.predict(X_test)

y_pred

                                       ###SVM

from sklearn.svm import SVC
svc =  SVC(gamma=0.0001)
svc.fit(X_train, y_train)
y_pred=svc.predict(X_test)

from sklearn.metrics import confusion_matrix, accuracy_score,classification_report
cm=confusion_matrix(y_test,y_pred)
print(cm)
print("Accuracy=",accuracy_score(y_test,y_pred)*100)
print("Classification Report",classification_report(y_test,y_pred))

##Hyperparameter Tunning
param_grid={'C': [0.001,0.1,1],'kernel' : ['linear', 'poly', 'rbf']}

param_grid

from sklearn.model_selection import GridSearchCV
grid=GridSearchCV(svc, param_grid,refit=True,verbose=3)
grid.fit(X_train,y_train)

print('Best parameters: ', grid.best_params_)
print('Best estimators: ', grid.best_estimator_)
print('Best score: ', grid.best_score_)

##Using Best Estimator Display Confusion Matrix
svc =  SVC(C=0.8, gamma=0.0001, kernel='linear')
svc.fit(X_train, y_train)
y_pred=svc.predict(X_test)
from sklearn.metrics import confusion_matrix,classification_report,accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
print(classification_report(y_test,y_pred))
print("Accuracy= ",accuracy_score(y_test,y_pred))